{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfcf14-f16c-4ed6-abf3-2a2ef8dc8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0252241-3ddf-4a60-ab6a-569d05f7c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.5 MB 5.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/15.5 MB 3.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.4/15.5 MB 2.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 3.1/15.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.9/15.5 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.7/15.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 5.2/15.5 MB 3.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 6.0/15.5 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 7.1/15.5 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.9/15.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.2/15.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.5/15.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.5 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\GuruKrishna Upputuri\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\GuruKrishna Upputuri\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c928e-ca94-400f-8424-cf9d5430814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e2c165-0f82-4b18-b4f2-f62fc95460f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Found existing installation: h5py 3.11.0\n",
      "Uninstalling h5py-3.11.0:\n",
      "  Successfully uninstalled h5py-3.11.0\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting h5py==3.10.0\n",
      "  Downloading h5py-3.10.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading h5py-3.10.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, h5py\n",
      "Successfully installed h5py-3.10.0 numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.10.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy h5py -y\n",
    "!pip install numpy==1.26.4 h5py==3.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14d5f79c-c2fd-4a96-8c0f-faad9e399a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Found existing installation: h5py 3.10.0\n",
      "Uninstalling h5py-3.10.0:\n",
      "  Successfully uninstalled h5py-3.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall numpy h5py -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c765a1be-a1aa-40de-a936-fa3861f734e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting h5py==3.10.0\n",
      "  Using cached h5py-3.10.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached h5py-3.10.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: numpy, h5py\n",
      "Successfully installed h5py-3.10.0 numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.10.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4 h5py==3.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc34631c-f259-4e64-a23a-cf497a95a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8765 - loss: 0.4437 - val_accuracy: 0.9598 - val_loss: 0.1367\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1191 - val_accuracy: 0.9712 - val_loss: 0.0925\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0776 - val_accuracy: 0.9747 - val_loss: 0.0827\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0533 - val_accuracy: 0.9755 - val_loss: 0.0778\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0447 - val_accuracy: 0.9766 - val_loss: 0.0718\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "model.save(\"mnist_model.keras\")  # New format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b469665d-0bb3-4087-9e00-e2c11c51601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Predicted Digit: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your trained MNIST model\n",
    "model = load_model(\"mnist_model.h5\")  # or \"mnist_model.keras\" if you used the new format\n",
    "\n",
    "# Your image path\n",
    "img_path = r\"C:\\Users\\GuruKrishna Upputuri\\OneDrive\\Pictures\\Screenshots 1\\Screenshot 2025-08-02 233118.png\"\n",
    "# Read and preprocess image\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)   # Load as grayscale\n",
    "'''img = cv2.resize(img, (28, 28))                    # Resize to 28x28\n",
    "img = 255 - img                                    # Invert colors (MNIST is white-on-black)\n",
    "img = img / 255.0                                  # Normalize\n",
    "input_img = img.reshape(1, 28, 28)                 # Add batch dimension\n",
    "'''\n",
    "img = cv2.resize(img, (28, 28))\n",
    "img = 255 - img\n",
    "img = img / 255.0\n",
    "input_img = img.reshape(1, 28, 28)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(input_img)\n",
    "predicted_digit = np.argmax(prediction)\n",
    "\n",
    "# Show result\n",
    "print(f\"Predicted Digit: {predicted_digit}\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_digit}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2ac1df-bce7-4de3-9496-40b30749281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8733 - loss: 0.4313\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.1079\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0709\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0538\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0410\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0965\n",
      "Test accuracy: 0.98\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Predicted Digit: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 1. Load and prepare MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 2. Build the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# 4. Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "# 5. Load and preprocess custom image\n",
    "img_path = r\"C:\\Users\\GuruKrishna Upputuri\\OneDrive\\Pictures\\Screenshots 1\\Screenshot 2025-08-02 233304.png\"\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if img is None:\n",
    "    print(\"❌ Failed to load image. Check path.\")\n",
    "else:\n",
    "    # Resize to 28x28, invert colors, normalize\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = 255 - img\n",
    "    img = img / 255.0\n",
    "    input_img = img.reshape(1, 28, 28)  # Reshape for model\n",
    "\n",
    "    # 6. Predict\n",
    "    prediction = model.predict(input_img)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "\n",
    "    # 7. Show result\n",
    "    print(f\"Predicted Digit: {predicted_digit}\")\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_digit}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63498c5e-423e-4a5c-b915-ad1d9eba8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GuruKrishna Upputuri\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.4224\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1075\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0667\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0504\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0402\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0980\n",
      "Test accuracy: 0.98\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Predicted Digit: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 1. Load and prepare MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 2. Build the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# 4. Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "# 5. Load and preprocess custom image\n",
    "img_path = r\"C:\\Users\\GuruKrishna Upputuri\\OneDrive\\Pictures\\Screenshots 1\\Screenshot 2025-08-04 020816.png\"\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if img is None:\n",
    "    print(\"❌ Failed to load image. Check path.\")\n",
    "else:\n",
    "    # Resize to 28x28, invert colors, normalize\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = 255 - img\n",
    "    img = img / 255.0\n",
    "    input_img = img.reshape(1, 28, 28)  # Reshape for model\n",
    "\n",
    "    # 6. Predict\n",
    "    prediction = model.predict(input_img)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "\n",
    "    # 7. Show result\n",
    "    print(f\"Predicted Digit: {predicted_digit}\")\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_digit}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421ced1-99b9-4190-bf7b-a394ff3997a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
